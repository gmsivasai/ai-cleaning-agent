AI Data Cleaning Assistant

An end-to-end **AI-powered CSV Data Cleaning Assistant** that allows users to securely upload messy datasets, analyze common data quality issues, apply intelligent cleaning steps, and download cleaned files â€” all through a simple web interface.

---

## ğŸ“Œ Features

### ğŸ” Authentication & Security

* User **registration and login**
* **JWT-based authentication**
* Password hashing using **bcrypt**
* Input validation using **Pydantic**
* Protected routes with per-user file access

---

### ğŸ“¤ CSV Upload & Analysis

* Upload raw / messy CSV files
* Automatic detection of:

  * Missing values
  * Duplicate rows
  * Data types and inconsistencies
* Analysis results returned instantly

---

### ğŸ§  Intelligent Cleaning

* Smart cleaning agent (no ML models required)
* Supported cleaning steps:

  * Fill missing values
  * Remove duplicate rows
* User-selectable cleaning workflow
* Cleaned files stored securely per user

---

### ğŸ“¥ Downloads & History

* Download **cleaned CSV**
* Download **original CSV**
* View complete **file history**
* Secure access â€” users can only download their own files

---

### ğŸ“„ Cleaning Summary (Frontend-Only)

* Auto-generated cleaning summary
* Export summary as:

  * CSV
  * PDF
* No backend changes required for summary export

---

## ğŸ§° Tech Stack

### Backend

* **FastAPI** (async REST API)
* **SQLAlchemy + PostgreSQL**
* **JWT authentication**
* **Pydantic validation**
* **Pandas** for data processing

### Frontend

* **Streamlit**
* REST API integration using `requests`

### Security

* Password hashing: `passlib (bcrypt)`
* Token handling: `python-jose`

---

## ğŸ“ Project Structure

```
ai-data-cleaning-backend/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”‚
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â”œâ”€â”€ deps.py
â”‚   â”‚   â””â”€â”€ security.py
â”‚   â”‚
â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â”œâ”€â”€ temp_store.py
â”‚   â”‚   â””â”€â”€ history_router.py
â”‚   â”‚
â”‚   â””â”€â”€ cleaning/
â”‚       â”œâ”€â”€ analyze.py
â”‚       â””â”€â”€ agent.py
â”‚
â”œâ”€â”€ uploads/          # original CSV files
â”œâ”€â”€ cleaned/          # cleaned CSV files
â”‚
â”œâ”€â”€ frontend_streamlit.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_app.bat
â”œâ”€â”€ stop_app.bat
â””â”€â”€ README.md
```

---

## â–¶ï¸ How to Run the Application

### 1ï¸âƒ£ Activate virtual environment

```bash
venv\Scripts\activate
```

### 2ï¸âƒ£ Start backend

```bash
python -m uvicorn app.main:app --reload
```

### 3ï¸âƒ£ Start frontend

```bash
streamlit run frontend_streamlit.py
```

OR (recommended):

```bash
run_app.bat
```

---

## ğŸ›‘ Stop the Application

```bash
stop_app.bat
```

Safely stops both FastAPI and Streamlit processes.

---

## ğŸ§ª Demo Flow

1. Register a new user
2. Login
3. Upload a messy CSV file
4. Analyze dataset
5. Select cleaning steps
6. Clean & save file
7. Download cleaned CSV
8. View file history
9. Export cleaning summary (CSV / PDF)
10. Logout

---

## ğŸ”’ Validation Rules

* Email must be valid (`EmailStr`)
* Password:

  * Minimum **6 characters**
  * Cannot be empty or whitespace
* Unauthorized users cannot access files
* JWT tokens validated on every protected request

---

## ğŸ§  Design Highlights

* **Separation of concerns**

  * Validation â†’ Pydantic
  * Business logic â†’ Routers
  * Security â†’ JWT + hashing
  * UI â†’ Streamlit
* No frontend logic leaks into backend
* No backend changes required for UI enhancements

---

## ğŸš€ Future Enhancements (Optional)

* Password strength meter
* Strong password regex rules
* LangGraph-based multi-step cleaning orchestration
* Cloud storage (AWS S3)
* Admin dashboard
* Rate-limiting on login attempts

---

## ğŸ‘¨â€ğŸ’» Author

**Sivasai**
AI Data Cleaning Assistant Project

---
ğŸ¥ Demo Video:
https://drive.google.com/file/d/1BVzVAc6p_DW9spSXgeEb0y8jKNNjdc5N/view?usp=sharing

